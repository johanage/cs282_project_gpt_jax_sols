{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from jax import lax, random, numpy as jnp\n",
    "from flax import linen as nn\n",
    "from train.trainer import create_train_state, Trainer, load_train_state, save_train_state\n",
    "from model import GPT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('The input data has %d characters. %d of these characters are unique. These characters include uppercase and lower case letters, as well as punctuations.'\n",
    "        % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "        self.itos = {i:ch for i,ch in enumerate(chars)} # will be used for prediction/text generation task\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_block = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        encoded_txt = [self.stoi[char] for char in text_block]\n",
    "        x = torch.tensor(encoded_txt[:-1], dtype=torch.int)\n",
    "        y = torch.tensor(encoded_txt[1:], dtype=torch.int)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100000#(len(self.data) - self.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data has 1115393 characters. 65 of these characters are unique. These characters include uppercase and lower case letters, as well as punctuations.\n"
     ]
    }
   ],
   "source": [
    "shakespeare_txt = open('./gpt_text_input/shakespeare.txt', 'r').read()\n",
    "\n",
    "dataset = TextDataset(shakespeare_txt, block_size = 48)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.9, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"n_layers\": 4,\n",
    "    \"n_head\": 4,\n",
    "    \"n_embd\": 48,\n",
    "    \"vocab_size\": dataset.vocab_size,\n",
    "    \"block_size\": dataset.block_size,\n",
    "    \"embd_pdrop\": 0.0\n",
    "}\n",
    "epochs=2\n",
    "continue_training_from_checkpoint=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = GPT(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "key1, key2, dropout_key = random.split(random.PRNGKey(1), 3)\n",
    "\n",
    "init_rng = {\"params\": key2, 'dropout' : dropout_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state = create_train_state(model, init_rng, config, key=dropout_key)\n",
    "\n",
    "if continue_training_from_checkpoint:\n",
    "    state = load_train_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(train_dataset, test_dataset, train_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1407/1407 [05:54<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy: 0.2386350929737091\n",
      "train_loss: 2.8138303756713867\n",
      "test_accuracy: 0.29055947065353394\n",
      "test_loss: 2.4855010509490967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 1345/1407 [05:15<00:14,  4.16it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    trainer.run_trainer(epochs=1)\n",
    "    save_train_state(trainer.train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "state=trainer.train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = trainer.metrics_history[\"train_loss\"]\n",
    "plt.plot(np.arange(0, len(train_loss), 1), train_loss, label=\"loss\")\n",
    "train_accuracy = trainer.metrics_history[\"train_accuracy\"]\n",
    "plt.plot(np.arange(0, len(train_accuracy), 1), train_accuracy, label=\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loss = trainer.metrics_history[\"test_loss\"]\n",
    "plt.plot(np.arange(0, len(test_loss), 1), test_loss, label=\"loss\")\n",
    "test_accuracy = trainer.metrics_history[\"test_accuracy\"]\n",
    "plt.plot(np.arange(0, len(test_accuracy), 1), test_accuracy, label=\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "x, y = next(iter(dataloader))\n",
    "sentence = \"\".join([dataset.itos[int(x_i)] for x_i in x[0]])\n",
    "print(x)\n",
    "print(\"input sentence: \", sentence)\n",
    "print()\n",
    "x, y = jnp.array(x), jnp.array(y)\n",
    "sequence= model.generate(state.params, x, 96, key1, 0.4)\n",
    "    \n",
    "sentence = \"\".join([dataset.itos[x_i] for x_i in sequence])\n",
    "print(sentence)\n",
    "print(\", \".join([dataset.itos[i] for i in range(config[\"vocab_size\"])]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}