{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> Introduction to minGPT - A PyTorch re-implementation of GPT </h1>\n",
    "\n",
    "minGPT is originally a PyTorch re-implementation of GPT, a highly successful language modeling framework developed by OpenAI. Created by Andrej Karpathy, minGPT is a lightweight and efficient implementation of GPT, designed to be easy to use and highly customizable. With its modular architecture and flexible design, minGPT is a powerful tool for researchers and practitioners working in natural language processing and related fields. And don't worry, despite its name, minGPT is not small-minded! ;) \n",
    "<br/> This assignment will introduce you to the basics of minGPT and how to use it for language modeling tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "OpenAI’s generative pre-trained transformer (GPT) was first introduced in ”Improving Language\n",
    "Understanding by Generative Pre-Training” [1], and has since then developed into being one of the\n",
    "most topical models within the field of ML, and a common conversational topic on a global scale.\n",
    "Due to the significant societal impact that this model already has a lot of questions have been\n",
    "raised in the aftermath of its public release. This projects aim to make a homework assignment on\n",
    "the implementation of the model architecture and word embedding with an additional twist where\n",
    "we want to provoke students to make their own reflections on the societal impact of the model.\n",
    "\n",
    "<i> [1] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language\n",
    "understanding by generative pre-training. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> GPT (current) Gold Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before we dive into minGPT, let's look at the current gold-standard of GPT models, GPT-3.5. While there are several use cases of GPT, let's look at one of the most commonly used one, ChatGPT! ChatGPT is a large language model based on the GPT-3.5 architecture, trained by OpenAI to generate human-like text. It is designed to respond to human prompts with natural language responses, making it useful for a variety of applications such as chatbots, automated content generation, and more. Under the hood, ChatGPT uses a deep neural network to learn from massive amounts of data, allowing it to generate text that is coherent and contextually relevant\n",
    "<br/> You can interact with ChatGPT here: http://chat.openai.com (sign up using Google and your Berkeley account).\n",
    "<br/>\n",
    "Have a short conversation with ChatGPT about Transformers, GPT models, and the basic workings of ChatGPT. Limit your conversation to three questions. \n",
    "<br/><br/><b> Answer the following questions: </b>\n",
    "1. What questions did you ask ChatGPT?\n",
    "2. In 2-3 sentences, what did you learn from the conversation?\n",
    "3. Were you satisfied with the responses? On a scale of 1-5, rate the conversation you had with ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that you have interacted with ChatGPT, let's work on a much more simple and scaled-down version, minGPT! In this assignment, we will train minGPT to be a character-level language model on some arbitrary text input. \n",
    "<br/> <h5> Flax and Jax </h4>\n",
    "In this homework, we will be exploring the world of [Flax](http://flax.readthedocs.io/) and [Jax](https://github.com/google/jax), two powerful deep learning libraries made by Google that can be used to reimplement the PyTorch version of minGPT. Jax and Flax are both built on the concept of functional programming and provide a high-level interface for building and training neural networks, which can simplify the development process and reduce the amount of boilerplate code that needs to be written. Flax and Jax are designed to take advantage of modern hardware architectures such as GPUs and TPUs, which can significantly speed up the training process and reduce the time-to-deployment for new models.\n",
    "<br/> By using these libraries, you will gain a deeper understanding of the underlying principles of neural networks and develop your skills in functional programming. You will also have the opportunity to compare and contrast the PyTorch and Flax/Jax versions of minGPT, gaining valuable insights into the similarities and differences between these powerful tools. So let's roll up our sleeves and dive into the world of Flax and Jax!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h4> Train a character-level GPT on some text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.5)\r\n",
      "Requirement already satisfied: jax in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.4.8)\r\n",
      "Requirement already satisfied: jaxlib in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.4.7)\r\n",
      "Requirement already satisfied: flax in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.6.8)\r\n",
      "Requirement already satisfied: optax in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.1.4)\r\n",
      "Requirement already satisfied: dm-haiku in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.0.9)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.0.0)\r\n",
      "Requirement already satisfied: clu in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.0.8)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (4.65.0)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (3.7.1)\r\n",
      "Requirement already satisfied: jupyter in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (1.0.0)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in ./venv/lib/python3.9/site-packages (from jax->-r requirements.txt (line 2)) (0.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.7 in ./venv/lib/python3.9/site-packages (from jax->-r requirements.txt (line 2)) (1.10.1)\r\n",
      "Requirement already satisfied: opt-einsum in ./venv/lib/python3.9/site-packages (from jax->-r requirements.txt (line 2)) (3.3.0)\r\n",
      "Requirement already satisfied: msgpack in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (1.0.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (4.5.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (6.0)\r\n",
      "Requirement already satisfied: rich>=11.1 in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (13.3.4)\r\n",
      "Requirement already satisfied: orbax in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (0.1.7)\r\n",
      "Requirement already satisfied: tensorstore in ./venv/lib/python3.9/site-packages (from flax->-r requirements.txt (line 4)) (0.1.35)\r\n",
      "Requirement already satisfied: absl-py>=0.7.1 in ./venv/lib/python3.9/site-packages (from optax->-r requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: chex>=0.1.5 in ./venv/lib/python3.9/site-packages (from optax->-r requirements.txt (line 5)) (0.1.7)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./venv/lib/python3.9/site-packages (from dm-haiku->-r requirements.txt (line 6)) (0.9.0)\r\n",
      "Requirement already satisfied: jmp>=0.0.2 in ./venv/lib/python3.9/site-packages (from dm-haiku->-r requirements.txt (line 6)) (0.0.4)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (2.14.3)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.7.91)\r\n",
      "Requirement already satisfied: triton==2.0.0 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (2.0.0)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (3.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (3.12.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.7.101)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.7.4.91)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.4.0.1)\r\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (10.2.10.91)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (8.5.0.96)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (3.1.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (11.10.3.66)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.9/site-packages (from torch->-r requirements.txt (line 7)) (10.9.0.58)\r\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 7)) (60.2.0)\r\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 7)) (0.37.1)\r\n",
      "Requirement already satisfied: lit in ./venv/lib/python3.9/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 7)) (16.0.1)\r\n",
      "Requirement already satisfied: cmake in ./venv/lib/python3.9/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 7)) (3.26.3)\r\n",
      "Requirement already satisfied: etils[epath] in ./venv/lib/python3.9/site-packages (from clu->-r requirements.txt (line 8)) (1.2.0)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from clu->-r requirements.txt (line 8)) (23.1)\r\n",
      "Requirement already satisfied: ml-collections in ./venv/lib/python3.9/site-packages (from clu->-r requirements.txt (line 8)) (0.1.1)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.9/site-packages (from clu->-r requirements.txt (line 8)) (1.14.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.0.9)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.39.3)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (5.12.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (2.8.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.0.7)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 10)) (9.5.0)\r\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (6.22.0)\r\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (8.0.6)\r\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (7.3.1)\r\n",
      "Requirement already satisfied: qtconsole in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (5.4.2)\r\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (6.5.4)\r\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.9/site-packages (from jupyter->-r requirements.txt (line 11)) (6.6.3)\r\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in ./venv/lib/python3.9/site-packages (from chex>=0.1.5->optax->-r requirements.txt (line 5)) (0.1.8)\r\n",
      "Requirement already satisfied: toolz>=0.9.0 in ./venv/lib/python3.9/site-packages (from chex>=0.1.5->optax->-r requirements.txt (line 5)) (0.12.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 10)) (3.15.0)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 10)) (1.16.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.9/site-packages (from rich>=11.1->flax->-r requirements.txt (line 4)) (2.15.0)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in ./venv/lib/python3.9/site-packages (from rich>=11.1->flax->-r requirements.txt (line 4)) (2.2.0)\r\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (1.5.6)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (5.9.0)\r\n",
      "Requirement already satisfied: tornado>=6.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (6.1)\r\n",
      "Requirement already satisfied: pyzmq>=20 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (25.0.2)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (1.6.7)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (7.3.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (0.1.6)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (8.12.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (5.3.0)\r\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (5.9.5)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r requirements.txt (line 11)) (0.1.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 11)) (4.0.7)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 11)) (3.0.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch->-r requirements.txt (line 7)) (2.1.2)\r\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (3.0.38)\r\n",
      "Requirement already satisfied: contextlib2 in ./venv/lib/python3.9/site-packages (from ml-collections->clu->-r requirements.txt (line 8)) (21.6.0)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.2.2)\r\n",
      "Requirement already satisfied: tinycss2 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (1.2.1)\r\n",
      "Requirement already satisfied: nbformat>=5.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (5.8.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (6.5.0)\r\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (2.0.5)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (1.5.0)\r\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.7.3)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (4.12.2)\r\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (6.0.0)\r\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.7.1)\r\n",
      "Requirement already satisfied: ipython-genutils in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.2.0)\r\n",
      "Requirement already satisfied: argon2-cffi in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (21.3.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (1.8.0)\r\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.5.5)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.17.1)\r\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.9/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.16.0)\r\n",
      "Requirement already satisfied: cached_property in ./venv/lib/python3.9/site-packages (from orbax->flax->-r requirements.txt (line 4)) (1.5.2)\r\n",
      "Requirement already satisfied: qtpy>=2.0.1 in ./venv/lib/python3.9/site-packages (from qtconsole->jupyter->-r requirements.txt (line 11)) (2.3.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.9/site-packages (from sympy->torch->-r requirements.txt (line 7)) (1.3.0)\r\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.6.2)\r\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (5.1.1)\r\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.7.5)\r\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (4.8.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.18.2)\r\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.2.0)\r\n",
      "Requirement already satisfied: entrypoints in ./venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r requirements.txt (line 11)) (0.4)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./venv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r requirements.txt (line 11)) (3.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.9/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax->-r requirements.txt (line 4)) (0.1.2)\r\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in ./venv/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (0.2.2)\r\n",
      "Requirement already satisfied: jupyter-server>=1.8 in ./venv/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (1.24.0)\r\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./venv/lib/python3.9/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 11)) (4.17.3)\r\n",
      "Requirement already satisfied: fastjsonschema in ./venv/lib/python3.9/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 11)) (2.16.3)\r\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.2.6)\r\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 11)) (0.7.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./venv/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 11)) (21.2.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 11)) (2.4.1)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 11)) (0.5.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.8.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 11)) (23.1.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./venv/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 11)) (0.19.3)\r\n",
      "Requirement already satisfied: websocket-client in ./venv/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (1.5.1)\r\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in ./venv/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (3.6.2)\r\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./venv/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 11)) (1.15.1)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 11)) (0.2.2)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.9/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (1.3.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.9/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 11)) (3.4)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 11)) (2.21)\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.1 is available.\r\n",
      "You should consider upgrading via the '/home/espen/PycharmProjects/cs282_project_gpt_jax/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# First, some imports!\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(182)\n",
    "\n",
    "\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to coding in jax and flax\n",
    "Before we start implementing the GPT architecture the libraries `jax` [jax link](https://jax.readthedocs.io/en/latest/index.html) and `flax` [flax link](https://flax.readthedocs.io/en/latest/) should be introduced as they have some key differences from pytorch functionalities. These differences are explained in detaile [here](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Random-Numbers). \n",
    "\n",
    "First let us start with `jax`. In practice `jax` works almost exactly as `numpy` but use own datatypes which is more convenient in the context of high-performance numerical computing (HPC). Experience with such libraries is crucial as modern ML applications require resources that is beoynd the capabilities of a personal computer. Furthermore, `jax` supports automatic differentiation in both forward- and reverse-mode as well as accelerated linear algebra (XLA - domain-specific compiler [XLA link](https://www.tensorflow.org/xla)) .\n",
    "\n",
    "## Random number generation\n",
    "\n",
    "The first difference between `jax` and `numpy` we are going to highlight is ***how you generate random numbers***. In the code block below we demonstrate how you generate a random vector $x, x\\in\\mathbb{R}^{10}, x_i \\sim \\mathcal{N}(0,1)$. You can read more about the PRNG design [here](https://github.com/google/jax/blob/main/docs/jep/263-prng.md). A major advantage of this design is **reproducible program execution in a backend-indpendent way**. This is of major imortance for validating new discoveries within ML research as a many components (weight and bias initialization, dropout, masking, etc.) depend on PRNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([ 0.690805  , -0.48744103, -1.155789  ,  0.12108463, -0.19598432,\n",
       "       -0.5078766 ,  0.91568655,  1.70968   , -0.36749417,  0.14315689],      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import random\n",
    "size = (10,)\n",
    "key = random.PRNGKey(1)\n",
    "# generate random vector with std normal distributed elements\n",
    "x = random.normal(key, size)\n",
    "x\n",
    "# alternatively use a mu sigma^2 normal distributed vector\n",
    "# x = mu + sigma2*random.normal(key,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To prevent generating random numbers from the same state represented by the variable `key`, the PRNG is split to get usable subkeys every time a new pseudorandom number is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old key [0 1]\n",
      "    \\---SPLIT --> new key    [2441914641 1384938218]\n",
      "             \\--> new subkey [3819641963 2025898573] --> normal [-1.1470195]\n"
     ]
    }
   ],
   "source": [
    "# copied from hax common gotchas\n",
    "print(\"old key\", key)\n",
    "key, subkey = random.split(key)\n",
    "normal_pseudorandom = random.normal(subkey, shape=(1,))\n",
    "print(\"    \\---SPLIT --> new key   \", key)\n",
    "print(\"             \\--> new subkey\", subkey, \"--> normal\", normal_pseudorandom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pure functions\n",
    "\n",
    "`jax` is a language of expressing and composing transformations of numerical programs and compile these programs for both CPU and accelerators (GPU/TPU). Compiling across devices requires that the code is written with certain constraints. One of the constraings is that the transformations and compilations are designed to only work on ***pure functions*** [pure functions link](https://en.wikipedia.org/wiki/Pure_function). This means that all the input data is passed through the function parameters, all the results are output throught hte functions results. Consequently, a pure function will always give the same output for the same input. In the below code block we have provided some examples of impure functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "[11.]\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "# using global\n",
    "global_var = 1\n",
    "def impure_input_is_output(x):\n",
    "    return x + global_var\n",
    "# uses initial assignment of the global variable\n",
    "print(jit(impure_input_is_output)(1))\n",
    "global_var = 10.\n",
    "# subsequent runs may cached value of the previous print\n",
    "print(jit(impure_input_is_output)(2))\n",
    "# when the type is changed the las update of the global variable is used\n",
    "print(jit(impure_input_is_output)(jnp.array([1]) ) )\n",
    "\n",
    "############\n",
    "# Add more #\n",
    "# examples #\n",
    "############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In-place updates\n",
    "\n",
    "Another important difference to `numpy` is how in-place update are done. `jax` offers a functional array update using the `.at` property. This difference is examplified in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#### Jax #####\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# not that float 64 is not available, try by running the\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# commented-out line below\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#jnp_arr = jnp.zeros((3,3), dtype = jnp.float64)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m jnp_arr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), dtype \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mjnp_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/cs282_project_gpt_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:263\u001b[0m, in \u001b[0;36m_unimplemented_setitem\u001b[0;34m(self, i, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unimplemented_setitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, x):\n\u001b[1;32m    259\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object does not support item assignment. JAX arrays are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimmutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor another .at[] method: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: '<class 'jaxlib.xla_extension.ArrayImpl'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "#### Numpy #####\n",
    "np_arr = np.zeros((3,3), dtype=np.float64)\n",
    "print(np_arr)\n",
    "# in place, mutating update\n",
    "np_arr[1,:] = 1\n",
    "print(np_arr)\n",
    "\n",
    "#### Jax #####\n",
    "# not that float 64 is not available, try by running the\n",
    "# commented-out line below\n",
    "#jnp_arr = jnp.zeros((3,3), dtype = jnp.float64)\n",
    "jnp_arr = jnp.zeros((3,3), dtype = jnp.float32)\n",
    "jnp_arr[1,:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### correct jax in-place update ####\n",
    "jnp_arr.at[1,:].add(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Permissive inputs\n",
    "\n",
    "`jax` requires premissive inputs. While `numpy` accepts lists or tuples as inputs, `jax` do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sum([1,1,1]))\n",
    "jnp.sum([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# first convert to jnp array and then sum\n",
    "print(jnp.sum(jnp.array([1,1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Out-of-bounds indexing\n",
    "For out-of-bound indexing `numpy` provides an error clearly explaining the error. In `jax` this is not so simple as raising an error from an accelerator (GPU/TPU) might be impossible or very difficult. Therefore, updates out-of-bounds will be skipped and the values will be filled with some value (in some cases the last value of the array but the behaviour is undefined) or some user-defined fill value using `.at[index].get(mode='fill', fill_value=fill_value')`. **Note** that when doing reverse mode automatic differentiation which turns index updates into index retrievals and vice versa will not preserve the semantics of out of bounds indexing. Therefore, out-of-bounds indexing should be thought of as undefined behaviour in `jax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.arange(10)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Simple indexing: \", jnp.arange(10)[10])\n",
    "print(\"Using the ndarray at: \", jnp.arange(10).at[11].get())\n",
    "print(\"Using the ndarray at and fill values out-of-bounds with nan's: \",jnp.arange(10.0).at[11].get(mode='fill', fill_value=jnp.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Flax introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model parameters and initialization\n",
    "Parameters are not stored with the models themselves. You need to initialize parameters by calling the `init` function, using a PRNGKey and dummy input data. The parameter will have the shape of a nested dictionary whose leaves are `jax.numpy.array`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax\n",
    "model = nn.Dense(features = 4)\n",
    "key1, key2 = random.split(random.PRNGKey(1), 2)\n",
    "minval, maxval = 0,10\n",
    "# generate a randomly initialized input\n",
    "x = random.randint(key1, (4, 10), minval, maxval)\n",
    "# initialiaze the parameters\n",
    "params = model.init({'params' : key2}, x)\n",
    "# Checking output shapes\n",
    "jax.tree_util.tree_map(lambda x: x.shape, params) \n",
    "# apply the model on the input data\n",
    "y = model.apply(params, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Note the following about the above code block\n",
    "- the RNG has to be passed in the `model.init` function as the first argument if you are not explicitly using keyword and then the the input data\n",
    "- when applying the model on the input data additional RNGs as to be passed as a dictionary using the keyword `rngs = {'prng_name' : prng_key}` where the name is the same as you used when initializing the parameters\n",
    "- all the RNGs that is going to be used in the model has to be initialized in the `model.init`-function\n",
    "\n",
    "## Setting the parameters manually\n",
    "1. flatten the parameter dictionary\n",
    "2. edit the flattened parameters by setting new values to keys given by the flattened parameter dictionary\n",
    "3. unflatten the parameters\n",
    "4. freeze the parameters\n",
    "5. now the paremeters can be applied to the same model with different values.\n",
    "\n",
    "**Note** in the fully connected layers of the MLP the dimensions are flipped due to an implementation choice in `jax`, advice [here](https://flax.readthedocs.io/en/latest/advanced_topics/convert_pytorch_to_flax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from flax import traverse_util\n",
    "from flax.core import freeze\n",
    "# Get a flattened key-value list.\n",
    "flat_params = traverse_util.flatten_dict(params, sep='/')\n",
    "print(\"Flattened parameter tree: \\n\", jax.tree_util.tree_map(jnp.shape, flat_params) )\n",
    "# edit the parameters\n",
    "print('Before bias is assigned values : ', flat_params['params/bias'])\n",
    "flat_params['params/bias'] = jnp.ones(flat_params['params/bias'].shape)\n",
    "print('After bias is assigned values : ', flat_params['params/bias'])\n",
    "\n",
    "# Unflatten.\n",
    "unflat_params = traverse_util.unflatten_dict(flat_params, sep='/')\n",
    "# Refreeze.\n",
    "unflat_params = freeze(unflat_params)\n",
    "jax.tree_util.tree_map(jnp.shape, unflat_params)\n",
    "# apply to model\n",
    "y_new = model.apply(unflat_params, x)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# note that the new output is different from the old\n",
    "print(\"old - new output: \", y - y_new)\n",
    "\n",
    "# and that we still can apply the previous params to get the same result\n",
    "print(\"old - model applied on same old parameters : \", y - model.apply(params, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> 1. Attention is all we need!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section, we are going to be focusing specifically on the attention mechanism that is at the heart of its architecture. Attention is a critical component of many modern neural networks, and it plays a particularly important role in natural language processing tasks such as language modeling and machine translation. By completing this section of the homework, you will gain a deeper understanding of how attention works and how it can be used to improve the performance of language models. \n",
    "<br/>You will now implement the causal self attention for (min) GPT! You will implmement the code in the `model/model.py` file. Read the instructions in the docstring and then fill in the code in the places that says `#YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some tests here\n",
    "from tests.test_attention import TestAttention\n",
    "TestAttention().autograde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> 2. Unpacking the MLP: Layer by Layer for Better Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The multi-layer perceptron (MLP) in GPT, also known as the feedforward network, is an essential component that helps to improve the model's ability to learn from sequential data. While the self-attention mechanism in GPT allows the model to attend to different parts of the input sequence, the MLP is responsible for processing and transforming the attended features before they are fed into the next layer. This additional non-linearity helps to capture more complex patterns and dependencies between the input tokens, leading to better performance on a wide range of language modeling tasks.\n",
    "<br/> In this section, you are going to implement the MLP for (min) GPT! You will implmement the code in the `model/model.py` file. Read the instructions in the docstring and then fill in the code in the places that says `#YOUR CODE HERE`.\n",
    "<br/> HINT: Read the documentation [here](https://flax.readthedocs.io/en/latest/api_reference/_autosummary/flax.linen.Dense.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some tests here\n",
    "from tests.test_mlp import TestMLP\n",
    "TestMLP().autograde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> 3. From Text to Numbers: Understanding Encoding in Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The encoding section focuses on one of the most important aspects of natural language processing: converting textual data into numerical representations that can be understood and processed by machine learning models. In this section, we will explore the different types of encoding methods commonly used in NLP, including one-hot encoding, word embeddings, and more. By the end of this section, you should have a better understanding of how encoding works and why it is crucial for many language-based applications. You will implmement the code in the `encoding/bpe.py` file. Read the instructions in the docstring and then fill in the code in the places that says `#YOUR CODE HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# some tests here\n",
    "from tests.test_encoding import TestEncoder\n",
    "TestEncoder().autograde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> 4. Crossing the Finish Line: Completing the MinGPT model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We're almost there! In this section, you will complete the final parts of the minGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tests import test_set_params\n",
    "# run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's run some unittests to see if your implementation is correct!\n",
    "from tests import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> 5. Unleashing the power of minGPT: Training (and testing) the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now train minGPT to be a character-level language model on some input text file. The input text file is an extract of Shakespearean text of about 1.1 MB. <br/> To use minGPT as a character level language model, we first preprocess the input text by converting it into a sequence of characters. We then train the model to predict the next character in the sequence given the preceding characters as input. Once the model is trained, we can use it to generate new text by feeding it a starting sequence (context) and iteratively sampling new characters from the model's predicted distribution until the desired length of text is generated. By using minGPT as a character level language model, we can generate new text that is similar in style and content to the input data, making it a useful tool for tasks such as text generation, language modeling, and autocompletion tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('The input data has %d characters. %d of these characters are unique. These characters include uppercase and lower case letters, as well as punctuations.'\n",
    "        % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "        self.itos = {i:ch for i,ch in enumerate(chars)} # will be used for prediction/text generation task\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_block = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        encoded_txt = [self.stoi[char] for char in text_block]\n",
    "        x = torch.tensor(encoded_txt[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(encoded_txt[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data) - self.block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now load the input Shakespearean text file and look at the composition of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data has 1115393 characters. 65 of these characters are unique. These characters include uppercase and lower case letters, as well as punctuations.\n"
     ]
    }
   ],
   "source": [
    "# Let's load in the input data of Shakespearean text\n",
    "shakespeare_txt = open('./gpt_text_input/shakespeare.txt', 'r').read() \n",
    "dataset = TextDataset(shakespeare_txt, block_size = 64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Go through the `train_config.py` file in the `train` directory. It contains the parameters we will use to train the model. You can play aroud with these parameters after you have trained the model for the first time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the model and the training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:46:40.674108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from train.trainer import create_train_state, Trainer\n",
    "from model import GPT\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.9, 0.1))\n",
    "\n",
    "param_key, generation_key, dropout_key = random.split(random.PRNGKey(1), 3)\n",
    "\n",
    "init_rng = {\"params\": param_key, 'dropout' : dropout_key}\n",
    "\n",
    "model_config = {\n",
    "    \"n_layers\": 6,\n",
    "    \"n_head\": 6,\n",
    "    \"n_embd\": 32*6,\n",
    "    \"vocab_size\": dataset.vocab_size,\n",
    "    \"block_size\": dataset.block_size,\n",
    "    \"embd_pdrop\": 0.1\n",
    "}\n",
    "\n",
    "num_epochs = 6\n",
    "\n",
    "model = GPT(**model_config)\n",
    "\n",
    "state = create_train_state(model, init_rng, model_config, key=dropout_key)\n",
    "trainer = Trainer(train_dataset, test_dataset, train_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/15685 [00:52<15:08:44,  3.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/cs282_project_gpt_jax/train/trainer.py:120\u001b[0m, in \u001b[0;36mTrainer.run_trainer\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_trainer\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset:\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_epoch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PycharmProjects/cs282_project_gpt_jax/train/trainer.py:140\u001b[0m, in \u001b[0;36mTrainer.run_epoch\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    138\u001b[0m     state \u001b[38;5;241m=\u001b[39m train_step(state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m    139\u001b[0m                        batch\u001b[38;5;241m=\u001b[39mbatch)  \u001b[38;5;66;03m# get updated train state (which contains the updated parameters)\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     state \u001b[38;5;241m=\u001b[39m compute_metrics(state\u001b[38;5;241m=\u001b[39mstate, batch\u001b[38;5;241m=\u001b[39mbatch)\n",
      "File \u001b[0;32m~/PycharmProjects/cs282_project_gpt_jax/venv/lib/python3.9/site-packages/flax/core/frozen_dict.py:162\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, keys, values)\u001b[0m\n\u001b[1;32m    157\u001b[0m   sorted_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict)\n\u001b[1;32m    158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    159\u001b[0m       [(jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mDictKey(k), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[k]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sorted_keys]\n\u001b[1;32m    160\u001b[0m   ), \u001b[38;5;28mtuple\u001b[39m(sorted_keys)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, keys, values):\n\u001b[1;32m    164\u001b[0m   \u001b[38;5;66;03m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;66;03m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, values)}, __unsafe_skip_copy__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    trainer.run_trainer(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plot the loss and accuracy on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loss = trainer.metrics_history[\"test_loss\"]\n",
    "plt.plot(np.arange(0, len(test_loss), 1), test_loss, label=\"loss\")\n",
    "test_accuracy = trainer.metrics_history[\"test_accuracy\"]\n",
    "plt.plot(np.arange(0, len(test_accuracy), 1), test_accuracy, label=\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now use the trained model to generate new text. Try experimenting with different input texts and temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "I found a love, for me\n",
    "Darling, just dive right in and follow my lead\n",
    "Well, I found a girl, beautiful and sweet\n",
    "\"\"\"\n",
    "temperature = 0.5\n",
    "tokens_to_generate = 128\n",
    "\n",
    "# Ensure that the input is the correct length:\n",
    "text = text.rjust(model_config[\"block_size\"])\n",
    "text = text[:model_config[\"block_size\"]]\n",
    "\n",
    "# Tokenize the input:\n",
    "x = np.array([[dataset.stoi[t] for t in text]])\n",
    "\n",
    "sentence = \"\".join([dataset.itos[int(x_i)] for x_i in x[0]])\n",
    "\n",
    "print(f\"input sequence:\\n{sentence}\")\n",
    "x = jnp.array(x)\n",
    "\n",
    "sequence= model.generate(state.params, x, tokens_to_generate, key1, temperature)\n",
    "\n",
    "sentence = \"\".join([dataset.itos[x_i] for x_i in sequence])\n",
    "print(f\"\\ngenerated sequence:\\n{sentence}\")\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b5e19b0de7feeb6e6bb5f9738d975aa3f5dabb2cb545fec106b49f43b6978a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
